{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Andrew Won's BI interview solution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame, Series\n",
      "import pandas as pd\n",
      "from datetime import datetime\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set pandas options, load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.notebook_repr_html', False)\n",
      "pd.set_option('display.max_columns', 20)\n",
      "pd.set_option('display.max_rows', 25)\n",
      "\n",
      "data = pd.read_csv(\"BI_Interview_Data-1.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create pandas objects to format and store dates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subbed = Series([isinstance(item, str) for item in data.subscription_date])\n",
      "\n",
      "trial_time = Series(index = xrange(len(data)), dtype=str)\n",
      "sub_time = Series(index = xrange(len(data)), dtype=str)\n",
      "time_to_sub = Series(index = xrange(len(data)), dtype = datetime)\n",
      "\n",
      "#binary classifier for trials resulting subscriptions\n",
      "data['subbed'] = Series([isinstance(item, str) for item in data.subscription_date]) \n",
      "\n",
      "FMT = '%m/%d/%Y %H'\n",
      "for i in range(len(data)):\n",
      "    trial_time[i] = datetime.strptime(data.trial_date[i] + ' ' + str(data.trial_hour[i]), FMT)\n",
      "    if isinstance(data.subscription_date[i], str):\n",
      "        sub_time[i] = datetime.strptime(data.subscription_date[i] + ' ' + str(int(data.sub_hour_start[i])), FMT)\n",
      "        time_to_sub[i] = (sub_time[i] - trial_time[i]).total_seconds()/3600\n",
      "    else: \n",
      "        sub_time[i] = 'No sub'\n",
      "        \n",
      "data['time_to_sub'] = Series(time_to_sub, dtype=float) # number of hours until sub\n",
      "data.trial_date = pd.to_datetime(data.trial_date)\n",
      "data['day'] = Series([d.day for d in data.trial_date]) # our trial cohorts\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Exploratory analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_to_sub.hist(bins=200) #distribution of time elapsed from trial to subscription\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x7d92bf0>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we can see the frequency at which hour after trial sign up (time_to_sub) the users subscribed. It's clear most subscribers sign up immediately within the first hour or two during the trial. Another spike occurs in the 300-350 hours range, which is the two-week mark and presumably when warnings and/or expired trials move people to subscribe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.day_of_week.value_counts().plot(kind='bar') \n",
      "data[data.subbed==True].day_of_week.value_counts().plot(kind='bar') \n",
      "sub_counts = pd.crosstab(data.day_of_week, data.subbed)\n",
      "sub_counts.plot(kind='bar', stacked=True, color=['green', 'gold'], grid = False)\n",
      "sub_counts.div(sub_counts.sum(1).astype(float), axis=0).plot(kind='barh', stacked=True, color=['black','gold'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0xa161870>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More exploration shows some variation in volume by day of the week, but (along with the trial date day) have little effect on subscription:no-subscription ratios."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped = data.groupby(data.day_of_week)\n",
      "grouped.agg(np.mean)\n",
      "data.pivot_table(rows=data.index, cols='day_of_week', values='time_to_sub').hist(bins=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([[<matplotlib.axes.AxesSubplot object at 0x0A04D770>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0A34A310>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0A6BAAF0>],\n",
        "       [<matplotlib.axes.AxesSubplot object at 0x0A368D90>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0A615930>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0A45D0D0>],\n",
        "       [<matplotlib.axes.AxesSubplot object at 0x0A4C49D0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0A5432B0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0A55EA70>]], dtype=object)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Still not much by day of the week; overall spikes hold the same in day_of_week distributions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "day_split = pd.crosstab(data.day, data.subbed)\n",
      "day_split.div(day_split.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True, color=['green', 'gold'], grid = False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0xc2e0550>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.pivot_table(rows=data.index, cols='day', values='time_to_sub').hist(bins=100) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[<matplotlib.axes.AxesSubplot object at 0x0C4E05F0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0C55E7F0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0C4DA770>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0C7F5F30>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0C5ED1D0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0C6190F0>],\n",
        "       [<matplotlib.axes.AxesSubplot object at 0x0C716870>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0C8F8AF0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0C967F90>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0C9A6650>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0C6F40D0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CA43FF0>],\n",
        "       [<matplotlib.axes.AxesSubplot object at 0x0CACC710>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CB460F0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CBBCA70>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CB570B0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CC62610>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CCDABD0>],\n",
        "       [<matplotlib.axes.AxesSubplot object at 0x0CD4A6F0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CDC1ED0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CDE48F0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CE301F0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CEA76D0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0CF0CDB0>],\n",
        "       [<matplotlib.axes.AxesSubplot object at 0x0CF8F5B0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D005BD0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D0356F0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D0B5090>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D08A310>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D194C10>],\n",
        "       [<matplotlib.axes.AxesSubplot object at 0x0D2581F0>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D272610>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D2A8B50>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D36B210>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D38EF30>,\n",
        "        <matplotlib.axes.AxesSubplot object at 0x0D3DF8D0>]], dtype=object)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally getting into our day cohorts we don't see much variation or obvious outliers in the sub:no-sub ratio by date. Distributions also holding out."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.pivot_table(rows=data.index, cols='trial_hour', values='time_to_sub').hist(bins=100)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I checked by hour to see if we could see if there is any difference when looking at the hour. (Perhaps night daytime triallers have more time to blog and will subscribe.) But without timezones we probably don't have enough data and the distribution confirms this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub_day = Series(index=data.index, dtype=str)\n",
      "for i in range(len(data)):\n",
      "    if 0.0 < data.time_to_sub[i] < 25.0:\n",
      "        sub_day[i] = 'day_one'\n",
      "    elif 360.0 > data.time_to_sub[i] >= 25.0:\n",
      "        sub_day[i] = 'during_trial'\n",
      "    elif data.time_to_sub[i] >= 360.0:\n",
      "        sub_day[i] = 'after_trial'\n",
      "    else:\n",
      "        sub_day[i] = 'no_sub'\n",
      "        \n",
      "data = data.join(pd.get_dummies(sub_day))\n",
      "\n",
      "grouped_date = data.groupby(data.trial_date)\n",
      "\n",
      "total_day_subs = grouped_date.day_one.agg(sum)\n",
      "total_trial_subs = grouped_date.during_trial.agg(sum)\n",
      "total_post_trial = grouped_date.after_trial.agg(sum)\n",
      "total_subs = total_day_subs + total_trial_subs + total_post_trial\n",
      "total_trials = grouped_date.no_sub.agg(sum) + total_subs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "Exception",
       "evalue": "columns overlap: Index([u'after_trial', u'day_one', u'during_trial', u'no_sub'], dtype=object)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-37-35404906659f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0msub_day\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'no_sub'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_day\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mgrouped_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4652\u001b[0m         \u001b[1;31m# For SparseDataFrame's benefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4653\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[1;32m-> 4654\u001b[1;33m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[0;32m   4655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4656\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4666\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[0;32m   4667\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4668\u001b[1;33m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[0;32m   4669\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy)\u001b[0m\n\u001b[0;32m     35\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                          copy=copy)\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_merge_doc\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m'\\nleft : DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;31m# this is a bit kludgy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_merge_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;31m# TODO: more efficiently handle group keys to avoid extra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36m_get_merge_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[0mlsuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         ldata, rdata = ldata._maybe_rename_join(rdata, lsuf, rsuf,\n\u001b[1;32m--> 281\u001b[1;33m                                                 copydata=False)\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_maybe_rename_join\u001b[1;34m(self, other, lsuffix, rsuffix, copydata)\u001b[0m\n\u001b[0;32m   2110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_rename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2111\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2112\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'columns overlap: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mto_rename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2114\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mlrenamer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mException\u001b[0m: columns overlap: Index([u'after_trial', u'day_one', u'during_trial', u'no_sub'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point we've narrowed down our obvious groups, which are those who sign up: <ul>\n",
      "<li>immediately,</li>\n",
      "<li>after the first day but during their trial period,</li>\n",
      "<li>after the trial expires,</li>\n",
      "<li>and those who don't sign up (presumably to-date).</li>\n",
      "</ul>\n",
      "So, I label each user and add dummy variables to our original dataframe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.corrcoef([total_day_subs, total_trial_subs, total_post_trial, total_subs, (total_subs/total_trials)])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'total_trials' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-38-c223d4d6a615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtotal_day_subs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_trial_subs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_post_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_subs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_subs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'total_trials' is not defined"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_day_subs.corr((total_trial_subs + total_post_trial))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "0.7858733609754418"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see some decent correlation coefficients, especially with the number of subs during the trial period (not including total_subs since it is inclusive). Since we're interested in making predictions after day one, I bring up the day-one vs. post-day-one relationship, which has a coefficient of about 0.79."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LinearRegression\n",
      "import pylab as pl\n",
      "import random\n",
      "\n",
      "random.seed(1)\n",
      "\n",
      "# Randomly assign training and testing groups, use somewhat arbitrary/commonly used 80/20% split\n",
      "randumb = random.sample(xrange(31),31)\n",
      "train = randumb[:24]\n",
      "test = randumb[24:]\n",
      "\n",
      "X1 = np.row_stack(total_day_subs) #formatting for sklearn OLS \n",
      "y1 = total_trial_subs + total_post_trial\n",
      "\n",
      "model = LinearRegression()\n",
      "model.fit(X1[train], y1[train])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus, using linear regresssion I train the model using randomly assigned training and testing samples..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Intercept: ', model.intercept_\n",
      "print 'Coefficients: ', model.coef_\n",
      "print(\"Residual sum of squares: %.2f\"\n",
      "      % np.mean((model.predict(X1[test]) - y1[test]) ** 2))\n",
      "print('Variance score: %.2f' % model.score(X1[test], y1[test]))\n",
      "\n",
      "pl.scatter(X1[test], y1[test],  color='black')\n",
      "pl.plot(X1[test], model.predict(X1[test]), color='blue',\n",
      "        linewidth=3)\n",
      "pl.xticks(())\n",
      "pl.yticks(())\n",
      "pl.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Intercept:  32.9188827695\n",
        "Coefficients:  [ 3.60157356]\n",
        "Residual sum of squares: 2681.76\n",
        "Variance score: 0.58\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>And now we have a fairly decent simple model to predict subscribers after gathering a full day's worth of data. Taking the number of immediate first day subscribers we can use the model to predict the total number of subscribers to follow, take the sum and divide by total number of trials. Though an even simpler model would work fairly well: the average. Mean conversion rate was at about 19% with low variance.</p>\n",
      "<p></p>\n",
      "\n",
      "<p>Attempting to improve accuracy of the model, I tested other relevant periods such as the middle of the trial period and the day of the trial expiration spike with little significance in terms of results. In some instances, highly dependent on the random selection of test/train samples, using the trial period of days 2 through 14 would improve R-squared, but since timing of the prediction is emphasized I stuck with using day one subs.</p>\n",
      "\n",
      "<p> Also with consideration with time, I tested the first two hours - where the largest spike occured - but did not find a better predictor.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}